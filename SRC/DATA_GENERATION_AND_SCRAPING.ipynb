{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Generated Resumes**"
      ],
      "metadata": {
        "id": "-r8WLRxBgKtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "id": "-aDVuwPGgLEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from faker import Faker\n",
        "\n",
        "API_KEY = \"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\"\n",
        "MODEL = \"mistralai/mistral-7b-instruct\"\n",
        "ENDPOINT = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "fake = Faker()\n",
        "job_titles = [\"frontend developer\",\n",
        "              \"backend developer\",\n",
        "              \"data analyst\",\n",
        "              \"DevOps engineer\",\n",
        "              \"ML engineer\"\n",
        "              \"full-stack developer\",\n",
        "              \"QA engineer\",\n",
        "              \"mobile developer\",\n",
        "              \"UI/UX designer\",\n",
        "              \"product analyst\"\n",
        "              ]\n",
        "\n",
        "portrayals = {\n",
        "    \"junior\": [\"real\", \"pretended to be mid\", \"pretended to be senior\"],\n",
        "    \"mid\": [\"underplayed\", \"real\", \"overhyped\"],\n",
        "    \"senior\": [\"pretended to be junior\", \"pretended to be mid\", \"real\"]\n",
        "}\n",
        "\n",
        "resumes = []\n",
        "\n",
        "for job_title in job_titles:\n",
        "    for source_level in [\"junior\", \"mid\", \"senior\"]:\n",
        "        for portrayal in portrayals[source_level]:\n",
        "\n",
        "            name = fake.name()\n",
        "            email = fake.email()\n",
        "            location = fake.city()\n",
        "\n",
        "            tone_instructions = \"\"\n",
        "\n",
        "            if source_level == \"senior\" and \"pretended\" in portrayal:\n",
        "                tone_instructions = \"\"\"Avoid strong leadership language like 'led', 'architected', 'managed'. Use supporting roles and technical focus. No mentoring or strategic decisions.\"\"\"\n",
        "            elif source_level == \"junior\" and portrayal == \"real\":\n",
        "                tone_instructions = \"\"\"Use humble tone, mention internships, coursework, or personal projects. Avoid advanced achievements, leadership, or scaling systems.\"\"\"\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "Write a professional and realistic resume in English for a candidate applying as a {job_title}.\n",
        "\n",
        "The candidate's actual experience level is {source_level}, but the resume should be written to **appear as if the candidate is {portrayal}**, using only real background and abilities.\n",
        "\n",
        "Important:\n",
        "- Do NOT mention or imply years of experience (e.g., \"3 years\", \"since 2021\", or date ranges like \"June 2020 - Jan 2021\")\n",
        "- Do NOT use terms like junior, mid-level, senior, or expert\n",
        "- Do NOT leave any placeholder fields (like Name, Email, or City) blank\n",
        "\n",
        "You must **not fabricate or exaggerate any experience**, only subtly change the **tone, phrasing, and structure** to match the intended impression.\n",
        "\n",
        "Candidate details:\n",
        "- Full name: {name}\n",
        "- Email: {email}\n",
        "- City: {location}\n",
        "\n",
        "Include the following sections:\n",
        "1. Professional Summary\n",
        "2. Work Experience (1‚Äì2 entries, based on actual ability)\n",
        "3. Education\n",
        "4. Skills\n",
        "\n",
        "{tone_instructions}\n",
        "\n",
        "Additional notes:\n",
        "- The resume should read as if written by a human.\n",
        "- Use varied sentence structure and vocabulary.\n",
        "- Keep it concise, flowing, and limited to a realistic one-page format.\n",
        "\n",
        "Return only the resume text ‚Äì no extra comments, markdown, or section labels like \"Resume\".\n",
        "Ensure the resume is complete and ends naturally with a final sentence. Avoid abrupt cutoff or partial sections.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "\n",
        "            data = {\n",
        "                \"model\": MODEL,\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "                \"max_tokens\": 300\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                response = requests.post(ENDPOINT, headers=HEADERS, json=data)\n",
        "                response.raise_for_status()\n",
        "                resp_json = response.json()\n",
        "\n",
        "                if \"choices\" not in resp_json or not resp_json[\"choices\"]:\n",
        "                    print(f\"‚ö†Ô∏è API error: {job_title} | {source_level} ‚Üí {portrayal}\")\n",
        "                    continue\n",
        "\n",
        "                content = resp_json[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "                resumes.append({\n",
        "                    \"job_title\": job_title,\n",
        "                    \"source_level\": source_level,\n",
        "                    \"portrayal\": portrayal,\n",
        "                    \"name\": name,\n",
        "                    \"email\": email,\n",
        "                    \"location\": location,\n",
        "                    \"resume_text\": content\n",
        "                })\n",
        "\n",
        "                print(f\"‚úÖ Done: {job_title} | {source_level} ‚Üí {portrayal}\")\n",
        "                time.sleep(2)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Exception for {job_title} | {source_level} ‚Üí {portrayal}: {e}\")\n",
        "\n",
        "# Save all resumes\n",
        "pd.DataFrame(resumes).to_csv(\"resumes.csv\", index=False)\n",
        "print(\"üéâ All resumes saved to resumes.csv\")\n"
      ],
      "metadata": {
        "id": "OKcGz6L2gLKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scraping Resumes**"
      ],
      "metadata": {
        "id": "ujBkmN4Mg9Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "headers = {\n",
        "        'accept': '*/*',\n",
        "        'accept-language': 'en-US,en;q=0.9',\n",
        "        'referer': 'https://www.hireitpeople.com/',\n",
        "        'sec-ch-ua': '\"Chromium\";v=\"136\", \"Google Chrome\";v=\"136\", \"Not.A/Brand\";v=\"99\"',\n",
        "        'sec-ch-ua-mobile': '?0',\n",
        "        'sec-ch-ua-platform': '\"Windows\"',\n",
        "        'sec-fetch-dest': 'script',\n",
        "        'sec-fetch-mode': 'no-cors',\n",
        "        'sec-fetch-site': 'cross-site',\n",
        "        'sec-fetch-storage-access': 'active',\n",
        "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',\n",
        "        'x-client-data': 'CKO1yQEIkrbJAQiktskBCKmdygEI0aDKAQi72coBCJKhywEIhaDNAQjd7s4B'\n",
        "    }\n",
        "\n",
        "\n",
        "def build_params(start, seniority):\n",
        "    return {\n",
        "        'rsz': 'filtered_cse',\n",
        "        'num': '10',\n",
        "        'hl': 'en',\n",
        "        'start': str(start),\n",
        "        'source': 'gcsc',\n",
        "        'cselibv': '75c56d121cde450a',\n",
        "        'cx': '003506502865988516570:i3u7tkb8dcq',\n",
        "        'q': seniority,\n",
        "        'safe': 'off',\n",
        "        'cse_tok': 'AB-tC_5rZOulMEYioXWIItaBrOvh:1746550407596',\n",
        "        'sort': '',\n",
        "        'exp': 'cc,apo',\n",
        "        'g-recaptcha-response': '...',\n",
        "        'callback': 'google.search.cse.api17176',\n",
        "        'rurl': 'https://www.hireitpeople.com/resume-database?q=senior',\n",
        "    }\n",
        "\n",
        "\n",
        "def extract_urls_from_response(response_text):\n",
        "    match = re.search(r'google\\.search\\.cse\\.\\w+\\((.*)\\);?$', response_text, re.S)\n",
        "    if not match:\n",
        "        raise ValueError(\"JSON body not found in response\")\n",
        "    json_str = match.group(1)\n",
        "    data = json.loads(json_str)\n",
        "    return [item[\"url\"] for item in data.get(\"results\", [])]\n",
        "\n",
        "\n",
        "def fetch_resume_data(url):\n",
        "    try:\n",
        "        req = requests.get(url)\n",
        "        if req.status_code != 200:\n",
        "            return None\n",
        "        soup = BeautifulSoup(req.content, 'html.parser')\n",
        "        resume_text = soup.find(class_=\"single-post-body\").text\n",
        "        job_title = soup.find(class_='media-body').find('h3').text.split(' Resume')[0]\n",
        "        return {'resume': resume_text, 'job title': job_title}\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def scrape_resumes(seniority, pages=10):\n",
        "    data_list = []\n",
        "    start = 0\n",
        "    for _ in range(pages):\n",
        "        params = build_params(start, seniority)\n",
        "        try:\n",
        "            response = requests.get('https://cse.google.com/cse/element/v1', params=params, headers=headers)\n",
        "            urls = extract_urls_from_response(response.text)\n",
        "            print(f\"Found URLs: {urls}\")\n",
        "            for url in urls:\n",
        "                data = fetch_resume_data(url)\n",
        "                if data:\n",
        "                    print(f\"Fetched: {data['job title']}\")\n",
        "                    data_list.append(data)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during scraping: {e}\")\n",
        "        start += 10\n",
        "    return data_list\n",
        "\n",
        "\n",
        "def save_to_excel(data, filename=\"senior.xlsx\"):\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_excel(filename, index=False)\n",
        "    print(f\"File saved successfully: {filename}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    all_data = []\n",
        "    for seniority_level in ['junior', 'mid', 'senior']:\n",
        "        all_data += scrape_resumes(seniority_level, pages=10)\n",
        "    save_to_excel(all_data)\n"
      ],
      "metadata": {
        "id": "KmbwggiZgLNo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}